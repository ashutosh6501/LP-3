# -*- coding: utf-8 -*-
"""3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18uJ6OsEEc0jpwY0vvhFWmcI7ofKZY5Ef

Sonal Shitole BC56

Given a bank customer, build a neural network-based classifier that can determine whether
they will leave or not in the next 6 months.
Dataset Description: The case study is from an open-source dataset from Kaggle.
The dataset contains 10,000 sample points with 14 distinct features such as
CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance, etc.

Link to the Kaggle project:
https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling
Perform following steps:
1. Read the dataset.
2. Distinguish the feature and target set and divide the data set into training and test sets.
3. Normalize the train and test data.
4. Initialize and build the model. Identify the points of improvement and implement the same.
5. Print the accuracy score and confusion matrix (5 points).
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as numpy
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("/content/drive/MyDrive/LP-3/ML/3/Churn_Modelling.csv")

"""PREPROCESSING"""

df.head()

df.shape

df.describe()

df.isnull()

df.isnull().sum()

df.info()

df.dtypes

df.columns

df.head()

"""VISUALIZATION"""

df.drop(["RowNumber","CustomerId","Surname"],axis=1,inplace=True)
df.head(5)

def visualization(x,y,xlabel):
  plt.hist([x,y],label =['exit','not_exit'])
  plt.xlabel(xlabel, fontsize=20)
  plt.ylabel("No. of customers", fontsize=20)
  plt.legend()

df_exited = df[df['Exited']==1]['Tenure']
df_not_exited = df[df['Exited']==0]['Tenure']

visualization(df_exited, df_not_exited,"Tenure")

df.Geography.unique()

"""CONVERTING THE CATEGORICAL VARIABLE"""

#  drop_first=True drops the first column during dummy variable creation.
#  Suppose, you have a column for gender that contains 4 variables- "Male", "Female", "Other", "Unknown". 
#  So a person is either "Male", or "Female", or "Other". If they are not either of these 3, their gender is "Unknown".
states = pd.get_dummies(df['Geography'] ,drop_first = True)
gender = pd.get_dummies(df['Gender'],drop_first = True)

df = pd.concat([df,gender,states], axis = 1)

"""SPLITTING THE TRAINING AND TESTING DATASET"""

df.head()

x = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts','HasCrCard','IsActiveMember']]

y=df['Exited']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.30,random_state=42)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

import keras
from keras.models import Sequential #To create sequential neural network
from keras.layers import Dense #To create hidden layers,neurons
seq=Sequential()

# The rectified linear activation function or ReLU for short is a piecewise linear function 
# that will output the input directly if it is positive, otherwise, it will output zero
# Units is to create the hidden layers
#Uniform helps to distribute the weight uniformly
seq.add(Dense(activation="relu" ,units=6 ,kernel_initializer="uniform"))

seq.add(Dense(activation = "relu",units = 6,kernel_initializer = "uniform"))   #Adding second hidden layers

seq.add(Dense(activation = "sigmoid",units = 1,kernel_initializer = "uniform")) #Final neuron will be having sigmoid function

seq.compile(optimizer="adam",loss = 'binary_crossentropy',metrics = ['accuracy']) 
#To compile the Artificial Neural Network.
#The compile() method takes a metrics argument, which is a list of metrics:
#Adam is an optimization algorithm to update network weights iterative based in training data.
#The Binary Cross entropy will calculate the cross-entropy loss between the predicted classes and the true classes.

seq.build(x.shape)

seq.summary() #3 layers created. 6 neurons in 1st,6neurons in 2nd layer and 1 neuron in last

seq.fit(X_train,y_train,batch_size=10,epochs=50) #Fitting the ANN to training dataset
#A good rule of thumb is to start with a value that is 3 times the number of columns in your data.
#An epoch means training the neural network with all the training data for one cycle.

y_pred =seq.predict(X_test)
y_pred = (y_pred > 0.5) #Predicting the result

from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cm = confusion_matrix(y_test,y_pred)
cm

accuracy = accuracy_score(y_test,y_pred)
accuracy

sns.heatmap(cm,annot = True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

print(classification_report(y_test,y_pred))